input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}

	kafka {
		bootstrap_servers => "172.20.125.78:9092"
		topics => ["logs-oht-alarm-filebeat-8.15.2", "logs-oht-command-filebeat-8.15.2"]
		codec => "json"
	}
}

## Add your filters / logstash plugins configuration here
filter {
	grok {
		match => { 
			"message" => [
				"%{TIME:[split_message][time]}\t%{GREEDYDATA:[split_message][level]}\t%{GREEDYDATA:[split_message][message]}\t%{GREEDYDATA:[split_message][code_line]}",
				"%{TIME:[split_message][time]}\t%{GREEDYDATA:[split_message][level]}\t%{GREEDYDATA:[split_message][message]}"
			]
		}
	}

	grok {
		match => {
			"[log][file][path]" => "/var/log/filebeat-log-source/%{GREEDYDATA:[oht][ip]}/%{GREEDYDATA:[oht][log_date]}/%{GREEDYDATA:[oht][log_type]}/%{GREEDYDATA:[oht][log_file]}"
		}
		add_field => {
			"[oht][log_timestamp]" => "%{[oht][log_date]} %{[split_message][time]}"
		}
	}

	date {
		match => ["[oht][log_timestamp]", "yyyyMMdd HH:mm:ss.SSS"]
		timezone => "Asia/Taipei"
		target => "@timestamp"
		remove_field => "[oht][log_timestamp]"
	}
}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
		data_stream => true
	}

	stdout {
		codec => rubydebug
	}
}
